---
title: "Final Project-Group 10"
author: "Luke Richard, Carter Parks, Carter Wolf, Amanda Ohmer"
date: "2024-03-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

**National Vehicle Crash Data**


**Introduction**

The goal of this project is to look into crash fatality rates compared to recorded variables in the United States. The National Highway Traffic Safety Administration (NHTSA) publishes national crash data for motor vehicles for each year with data from the Fatality Analysis Reporting System (FARS). Each crash recorded has many columns of data, keyed to the 'Fatality Analysis Report User Manual' (FARUM).

Through our research, we wanted to compare different factors related to fatality rate, such as speed, vehicle type, driver impairment, road conditions, and driver specifications. These variables likely have an effect on the outcome of crashes and could provide valuable insight into crash fatality rates. The fatality rate will be defined as the number of fatalities incurred in a crash over the number of total occupants involved. The other factors will then be related to this ratio in order to keep consistency across our findings.


**Data**

The link to the dataset is . The NHTSA has data from 1977 to 2022 published as individual .ZIP files, each containing multiple .CSV files. We chose to limit our data to the "vehicle" file, which contains information about the vehicles involved in the crashes, such as vehicle weight, number of occupants, number of fatalities, state where the crash occured, and the speed limit.

Since there are over 50,000 crashes in each of the "vehicle" files, we chose to limit our data to every 5 years, starting in 1975. This gave us 10 specific years of data. This will be interesting as we can track key variables over the last 45 years which should provide some insight into advances in safety and crash trends over time.


**Accumulation**

Since each of the "vehicle" files were in their own YEAR.zip file, they needed to be brought together for processing. To do this, the 10 years that we picked were downloaded from NHTSA and unzipped, then brought into RStudio individually as .csv files. Since the schemas changed over time, we removed columns from each specific year that were not important and edited inconsistent columns to give them a standardized format. This process can be seen below:


``` {r}
library(dplyr)
#vehicle75 <- read.csv("./FARS1975NationalCSV/VEHICLE.CSV")
#vehicle80 <- read.csv("./FARS1980NationalCSV/VEHICLE.CSV")
#vehicle85 <- read.csv("./FARS1985NationalCSV/VEHICLE.CSV")
#vehicle90 <- read.csv("./FARS1990NationalCSV/VEHICLE.CSV")
#vehicle95 <- read.csv("./FARS1995NationalCSV/VEHICLE.CSV")
#vehicle00 <- read.csv("./FARS2000NationalCSV/VEHICLE.CSV")
#vehicle05 <- read.csv("./FARS2005NationalCSV/VEHICLE.CSV")
#vehicle10 <- read.csv("./FARS2010NationalCSV/VEHICLE.CSV")
#vehicle15 <- read.csv("./FARS2015NationalCSV/vehicle.CSV")
#vehicle20 <- read.csv("./FARS2020NationalCSV/vehicle.CSV")

#vehicle75 <- vehicle75 %>% mutate(YEAR = 1975)
#vehicle80 <- vehicle80 %>% mutate(YEAR = 1980)
#vehicle85 <- vehicle85 %>% mutate(YEAR = 1985)
#vehicle90 <- vehicle90 %>% mutate(YEAR = 1990)
#vehicle95 <- vehicle95 %>% mutate(YEAR = 1995)
#vehicle00 <- vehicle00 %>% mutate(YEAR = 2000)
#vehicle05 <- vehicle05 %>% mutate(YEAR = 2005)
#vehicle10 <- vehicle10 %>% mutate(YEAR = 2010)
#vehicle15 <- vehicle15 %>% mutate(YEAR = 2015)
#vehicle20 <- vehicle20 %>% mutate(YEAR = 2020)

#vehicle75 <- vehicle75 %>%
#  select(-CHAS_TR, -MCYCL_TY, -DR_TRAIN, -VIOL_CHG, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle80 <- vehicle80 %>%
#  select(-CHAS_TR, -MCYCL_TY, -DR_TRAIN, -VIOL_CHG, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle85 <- vehicle85 %>%
#  select(-HAZ_CARG, -VEH_MAN, -L_CL_VEH, -VIN_BT, -DR_TRAIN, -VIOL_CHG, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle90 <- vehicle90 %>%
#  select(-HAZ_CARG, -VEH_MAN, -L_COMPL, -DR_ZIP, -VIN_BT, -VIOL_CHG, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle95 <- vehicle95 %>%
#  select(-MONTH, -UNDERIDE, -VIN_11, -VIN_12, -HAZ_CARG, -VEH_MAN, -L_COMPL, -DR_ZIP, -VIN_BT, -OWNER, -V_CONFIG, -AXLES, -CARGO_BT, -AVOID, -CDL_STAT, -L_ENDORS, -VIOL_CHG, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle00 <- vehicle00 %>%
#  select(-MONTH, -UNDERIDE, -VIN_11, -VIN_12, -HAZ_CARG, -VEH_MAN, -L_COMPL, -DR_ZIP, -VIN_BT, -OWNER, -V_CONFIG, -AXLES, -CARGO_BT, -AVOID, -CDL_STAT, -L_ENDORS, -BUS_USE, -GVWR, -MCARR_ID, -VIOLCHG1, -VIOLCHG2, -VIOLCHG3, -DR_CF4, -DR_WGT, -DR_HGT, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle05 <- vehicle05 %>%
#  select(-MONTH, -UNDERIDE, -VIN_11, -VIN_12, -HAZ_CARG, -VEH_MAN, -L_COMPL, -DR_ZIP, -VIN_BT, -OWNER, -V_CONFIG, -AXLES, -CARGO_BT, -AVOID, -CDL_STAT, -L_ENDORS, -BUS_USE, -GVWR, -MCARR_ID, -VIOLCHG1, -VIOLCHG2, -VIOLCHG3, -DR_CF4, -DR_WGT, -DR_HGT, -SEQ1, -SEQ2, -SEQ3, -SEQ4, -SEQ5, -SEQ6, -UNITTYPE, -L_TYPE, -FLDCD_TR, -IMPACTS, -TOWAWAY, -VEH_CF1, -VEH_CF2, -DR_CF1, -DR_CF2, -DR_CF3, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle10 <- vehicle10 %>%
#  rename(OCUPANTS = NUMOCCS)

#vehicle10 <- vehicle10 %>%
#  select(-MONTH, -UNDERIDE, -VIN_11, -VIN_12, -L_COMPL, -DR_ZIP, -VIN_BT, -OWNER, -V_CONFIG, -CARGO_BT, -CDL_STAT, -L_ENDORS, -BUS_USE, -GVWR, -MCARR_ID, -DR_WGT, -DR_HGT, -UNITTYPE, -L_TYPE,
 #        -DAY, -HOUR, -MINUTE, -VINTYPE, -VINMAKE, -VINMODYR,
 #        -FUELCODE, -MCARR_I1, -MCARR_I2, -HAZ_INV, -HAZ_PLAC, -HAZ_ID,
 #        -HAZ_CNO, -HAZ_REL, -ROLINLOC, -TOWED, -VEH_SC1, -VEH_SC2,
 #        -SPEEDREL, -DR_SF1, -DR_SF2, -DR_SF3, -DR_SF4, -VTRAFWAY,
 #        -VNUM_LAN, -VSPD_LIM, -VALIGN, -VPROFILE, -VPAVETYP, -VSURCOND,
 #        -VTRAFCON, -VTCONT_F, -P_CRASH1, -P_CRASH2, -P_CRASH3, -PCRASH4,
 #        -PCRASH5, -ACC_TYPE, -IMPACT2, -WGTCD_TR, -VIN_LNGT, -VIN_WGT, -WHLBS_SH, -WHLBS_LG, -MCYCL_DS, -SER_TR, -VINA_MOD, -PREV_SUS)

#vehicle15 <- vehicle15 %>%
  #rename(OCUPANTS = NUMOCCS)

#columns_15 <- colnames(vehicle15)
#columns_00 <- colnames(vehicle00)

# Find the common columns
#common_columns <- intersect(columns_15, columns_00)

# Select only the common columns from the first table
#vehicle15 <- vehicle15[, common_columns]

#vehicle20 <- vehicle20 %>%
 # rename(OCUPANTS = NUMOCCS)

#columns_20 <- colnames(vehicle20)

#common_columns <- intersect(columns_20, columns_00)

#vehicle20 <- vehicle20[, common_columns]


#over_time <- rbind(vehicle75, vehicle80, vehicle85, vehicle90, vehicle95, vehicle00, vehicle05, vehicle10, vehicle15, vehicle20)

#print(nrow(over_time))

#over_time

#write.csv(over_time, file="75-20_Data.csv", row.names = FALSE)
```

Importing tables in 5 year increments gave us a table containing data points from 10 different years (1975, 1980, ..., 2020). The entire table included around 550,000 records of crash data, each with 52 columns of information, which are keyed to in the "Fatality Analysis Report User Manual" pdf. This data accumulation was done with the script above and then stored in accumulation.R; that script creates 75-20_Data.csv which is read by this Rmd file so only one file (instead of 10 seperate files) is needed.

We set out with the intention of understanding how seatbelt laws effect fatality percentage in severe crashes. We intend to study the effects of seatbelt use nationwide, and on a state by state basis - looking out for correlations between state seatbelt laws and fatality percentage.

**Findings**

First we import the data, and begin to understand the dataset:

```{r}
over_time <- read.csv("./75-20_Data.csv")

#Entries Per Year
ggplot(data = over_time, aes(x = factor(YEAR))) + 
  geom_bar() +
  labs(title = 'Entries per Year', x = 'Year', y = 'Number of Entries') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Crash entries per year remained somewhat consistent, with around 60,000 crashes recorded each year. However there was a considerable dip in entries for 2010 and the following years.

In order to find the fatality rate, the number of deaths in a crash is devided by the number of occupants in the crash. Each crash will have a fatality rate, and a new column is made to store this number.

```{r}
#Fatality Rate By Year
finalData <- filter(over_time, `OCUPANTS` != 99 & `OCUPANTS` != 98)
finalData$FATALRATE <- (finalData$DEATHS/finalData$OCUPANTS)
#filter(finalData, FATALRATE < 10)
fatalfinal <- aggregate(FATALRATE ~ YEAR, filter(finalData, FATALRATE < 10), mean)

fatalfinal$YEAR <- as.numeric(as.character(fatalfinal$YEAR))
fatalfinal$FATALRATE <- as.numeric(as.character(fatalfinal$FATALRATE))
```
With fatality rate stored as FATALRATE, we can then create graphs to show aggregated fatality rates based on different variables.

```{r}
  #With linear model
ggplot(data = fatalfinal, aes(x = YEAR, y = FATALRATE)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = 'Fatality Rate per Year', x = 'Year', y = 'Fatality Rate') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

As we can see, fatality rate seems to have increased slightly over the last 50 years. However it's important to recognize the scale of the y axis, which indicates this is a marginal, yet recognizable change.

```{r}
#Entries by Death per Crash
ggplot(data = over_time, aes(x = factor(YEAR), fill = factor(DEATHS))) + 
  geom_bar() +
  labs(title = 'Entries per Year by Deaths per Crash', x = 'Year', y = 'Number of Crashes', fill = 'Number of Deaths') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here, we see that most entries are split evenly between 0 and 1 fatalities. There are some entries with 2 fatalities, and a very small percentage of entries have more than two fatalities.

```{r, include=FALSE}
statelab <- finalData
statelab$STATE <- as.factor(statelab$STATE)
statelab %>% group_by('STATE')
```

```{r}
#Entries by State
statelab %>% group_by('STATE') %>% 
  ggplot(aes(x = STATE)) +
  geom_bar() +
  labs(title = 'Entries per State', x = 'State', y = 'Number of Crashes') +
  scale_x_discrete(labels = c(
  "1" = "Alabama", "2" = "Alaska", "3" = "American Samoa", "4" = "Arizona",
  "5" = "Arkansas", "6" = "California", "8" = "Colorado", "9" = "Connecticut",
  "10" = "Delaware", "11" = "District of Columbia", "12" = "Florida",
  "13" = "Georgia", "14" = "Guam", "15" = "Hawaii", "16" = "Idaho",
  "17" = "Illinois", "18" = "Indiana", "19" = "Iowa", "20" = "Kansas",
  "21" = "Kentucky", "22" = "Louisiana", "23" = "Maine", "24" = "Maryland",
  "25" = "Massachusetts", "26" = "Michigan", "27" = "Minnesota",
  "28" = "Mississippi", "29" = "Missouri", "30" = "Montana",
  "31" = "Nebraska", "32" = "Nevada", "33" = "New Hampshire",
  "34" = "New Jersey", "35" = "New Mexico", "36" = "New York",
  "37" = "North Carolina", "38" = "North Dakota", "39" = "Ohio",
  "40" = "Oklahoma", "41" = "Oregon", "42" = "Pennsylvania",
  "43" = "Puerto Rico", "44" = "Rhode Island", "45" = "South Carolina",
  "46" = "South Dakota", "47" = "Tennessee", "48" = "Texas", "49" = "Utah",
  "50" = "Vermont", "51" = "Virginia", "52" = "Virgin Islands (Since 2004)",
  "53" = "Washington", "54" = "West Virginia", "55" = "Wisconsin",
  "56" = "Wyoming")) +
  theme(axis.text.x = element_text(hjust = 1))+
  coord_flip()
```

We wanted to know which states, if any stood out as particularly dangerous; above, we plot the total number of entries for each state. We found California, Texas, and Florida dominated the study and had by far the most entries. We also see a clear correlation between a state's population and the number of entries. This also included renaming the entire vector for state names, because they were encoded numerically.

```{r}

#Fatality Rate by State
statelab %>% group_by('STATE', 'FATALRATE') %>% 
  ggplot(aes(x = STATE)) +
  geom_bar(aes(weight = statelab$FATALRATE)) +
  labs(title = 'Fatality Rate per State', x = 'State', y = 'Fatality Rate') +
  scale_x_discrete(labels = c(
  "1" = "Alabama", "2" = "Alaska", "3" = "American Samoa", "4" = "Arizona",
  "5" = "Arkansas", "6" = "California", "8" = "Colorado", "9" = "Connecticut",
  "10" = "Delaware", "11" = "District of Columbia", "12" = "Florida",
  "13" = "Georgia", "14" = "Guam", "15" = "Hawaii", "16" = "Idaho",
  "17" = "Illinois", "18" = "Indiana", "19" = "Iowa", "20" = "Kansas",
  "21" = "Kentucky", "22" = "Louisiana", "23" = "Maine", "24" = "Maryland",
  "25" = "Massachusetts", "26" = "Michigan", "27" = "Minnesota",
  "28" = "Mississippi", "29" = "Missouri", "30" = "Montana",
  "31" = "Nebraska", "32" = "Nevada", "33" = "New Hampshire",
  "34" = "New Jersey", "35" = "New Mexico", "36" = "New York",
  "37" = "North Carolina", "38" = "North Dakota", "39" = "Ohio",
  "40" = "Oklahoma", "41" = "Oregon", "42" = "Pennsylvania",
  "43" = "Puerto Rico", "44" = "Rhode Island", "45" = "South Carolina",
  "46" = "South Dakota", "47" = "Tennessee", "48" = "Texas", "49" = "Utah",
  "50" = "Vermont", "51" = "Virginia", "52" = "Virgin Islands (Since 2004)",
  "53" = "Washington", "54" = "West Virginia", "55" = "Wisconsin",
  "56" = "Wyoming")) +
  coord_flip()
```

We also wanted to see if any states had particularly high fatality rates. Georgia, California, Texas, and Florida all stood out as having the highest fatality rates.

```{r}
#New York Graphs

newyorkfinal <-  aggregate(FATALRATE ~ YEAR, filter(filter(finalData, `STATE` == 36), FATALRATE < 10), mean)

  #New York per year by deaths per crash
ggplot(data = filter(finalData, `STATE` == 36), aes(x = factor(YEAR), fill = factor(DEATHS))) + 
  geom_bar() +
  labs(title = 'Entries per Year by Deaths per Crash', x = 'Year', y = 'Number of Crashes', fill = 'Number of Deaths') +
  theme(axis.text.x = element_text(hjust = 1))

```

Here, we filter our dataset to only contain values corresponding with New York. We'd like to see how this data compares to the whole dataset, and if there is a change in fatality rate after seatbelts were made mandatory in 1984.

```{r}
  #New York over time
ggplot(data = newyorkfinal, aes(x = factor(YEAR), y=factor(FATALRATE))) + 
  geom_point(show.legend = FALSE) +
  labs(title = 'New York Fatality Rate by Year', x = 'Year', y = 'Fatality Rate') +
  theme(axis.text.x = element_text(hjust = 1))

```

Here we plot New York's fatality rate over time. We find that while 1985 had a relatively low fatality rate in New York, it soon returned to normal levels by 1990 and 1995.

```{r}
#Fatality Rate per Model Year of Vehicle
modelfinal <- finalData %>% aggregate(FATALRATE ~ MOD_YEAR, mean) %>% filter(MOD_YEAR > 1922 & MOD_YEAR < 2023)

every_nth = function(n) {
  return(function(x) {x[c(TRUE, rep(FALSE, n - 1))]})
}

ggplot(data = modelfinal, aes(x = factor(MOD_YEAR), y = factor(FATALRATE))) + 
  geom_point() +
  labs(title = 'Fatality Rate per Model Year of Vehicle', x = 'Year', y = 'Fatality Rate') +
  scale_y_discrete(breaks=seq(0,1)) +
  scale_x_discrete(breaks = every_nth(n = 5)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1.1, size = 10))

```

This is one of the more interesting graphs we have. Vehicles made before 1975 have considerably higher fatality rates compared to modern vehicles. You can also notice a gradual reduction in fatality rate for vehicles made between 1980 and 2020

```{r}
#How deformed was vehicle
ggplot(data = filter(finalData, `DEFORMED` != 9), aes(x = factor(DEFORMED), fill = factor(DEATHS))) + 
  geom_bar() +
  labs(title = 'Deaths per crash vs. Deformation Amount', x = 'Deformation Amount', y = 'Number of Crashes') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(labels = c("0" = "No Damage", "2" = "Minor Damage", "4" = "Functional Damage", "6" = "Disabling Damage", "8" = "Not Recorded"))
```

This chart shows that for most entries, the vehicles were left in a disabled state, but there are also crashes recorded with more minor damage. In addition, we see that most crashes with disabling damage have zero or one death associated with the crash. It seems few crashes record 2 or more deaths.

```{r}
speedBins<- filter(finalData, TRAV_SP != 98 & TRAV_SP != 99)

speedBins <- mutate(speedBins, Speed_Bin = cut(TRAV_SP, breaks = seq(0, 100, by = 10), labels = paste(seq(0, 90, by = 10), "-", seq(10, 100, by = 10))))

# Plot the grouped bar chart
ggplot(speedBins, aes(x = Speed_Bin)) + 
  geom_bar() +
  labs(title = 'Number of Entries Grouped by Speed', x = 'Speed Bins', y = 'Number of Entries')

```

Here, we see all entries grouped by vehicle speed at the time of the crash. The majority of crashes take place at highway speeds and many were unknown.

```{r}
#Speeding
speed <- aggregate(FATALRATE ~ TRAV_SP,filter(finalData, `TRAV_SP` < 152 & `TRAV_SP` > -1), mean)

ggplot(data = speed, aes(x = factor(TRAV_SP), y = factor(FATALRATE))) +
  geom_point() +
  scale_y_discrete(breaks=seq(0,1)) +
  scale_x_discrete(breaks = every_nth(n = 5)) +
  labs(title = 'Fatality Rate vs. Travel Speed', x = 'Speed (MPH)', y = 'Fatality Rate') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This graph shows the average fatality rate by vehicle speed at the time of crash. We notice fatality rate begin to rise around 40 to 50 mph all the way up to 100 mph. At high speeds, there are limited entries and the outliers seem to spread out the data points- leading to unclear data above 100 mph.

```{r}
#Driver Drinking
aggregate(FATALRATE ~ DR_DRINK,filter(finalData, `DR_DRINK` !=9 & `FATALRATE` < 10), mean)
```

Occupants of a vehicle are twice as likely to die in a crash if the driver is drunk.

```{r}
#Driver restrictions
aggregate(FATALRATE ~ L_RESTRI,filter(finalData, `L_RESTRI`<4), mean)

```

Here, driver restrictions include any vision, curfew, or vehicle restrictions on a driver's licence. 0 and 1 correspond to restrictions being followed, 2 means restrictions were broken, and 3 means restrictions unknown. We notice accidents are 10 percent more fatal if the driver is breaking restrictions.

```{r}
#Towing Vehicle
aggregate(FATALRATE ~ TOW_VEH,filter(finalData, `TOW_VEH`<7), mean)

```

Here, we wanted to see if towing a trailer had an impact on the safety of the occupants. We notice that by simply having a trailer, the occupant of the vehicle was less likely to be killed in a crash. This may be because vehicles hauling trailers tend to be heavier and less susceptible to damage in collisions.

```{r}
#Vehicle Body Type
body <- aggregate(FATALRATE ~ BODY_TYP,filter(finalData, `BODY_TYP`<99), mean)

ggplot(data = filter(body, `BODY_TYP` == 1 | `BODY_TYP` == 4 | `BODY_TYP` == 80 | `BODY_TYP` == 50 | `BODY_TYP` == 10), aes(x = factor(BODY_TYP), y = factor(FATALRATE))) +
  geom_point() +
  labs(title = 'Fatality Rate per Body Type', x = 'Body Type', y = 'Fatality Rate') +
  scale_x_discrete(labels = c("1" = "Convertible", "4" = "Sedan", "80" = "Motorcycle", "50" = "Buses and Heavy Trucks", "10" = "Pickups")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we notice that a vehicle's weight has a major impact when it comes to the safety of it's occupants. Motorcycle crashes were particularly dangerous, with 9 fatalities for every 10 motorcycle crashes recorded. Classes of trucks were considerably safer than other vehicles.

Conclusion

Overall, our findings were slightly different from what we set out to see from the beginning. We expected to see a drop in fatality rate around 1980, when seatbelt laws first started getting made, but this was not apparent in our data. One thing we failed to take into account was how the data is being collected, as all of the recorded crashes were recorded by police on the scene. This means less serious crashes where fatalities are not present are much less likely to show up in the FARS data. The total population also is not a variable in the FARS data, and the US population has increased by over 125 million in the past 50 years [1] . With more people in the US, there are more drivers on the roads, increasing the probability of a crash occurring. Over the timespan of our data, the total vehicle miles traveled in the US increased from 1.3 billion miles to 3.2 billion, an increase of 146% [2]. In addition to an increase in miles traveled, the speed limit has been continuously on a rise since 1983 [3]. When fuel prices and scarcity problems were rising in 1974, a national speed limit of 55 MPH was adopted. In the 80s, fuel prices were less of a concern, and the speed limit was raised to 65 MPH on interstates. Speed limit lawmaking was returned to the states in 1995, and the limits have since increased, with texas having speed limits of 85 MPH on some inter-city roads. Our data showed that higher vehicle travel speeds drastically increase fatality rates, and the US is continuously driving faster. With modern vehicles being safer and more fuel efficient, it makes it easier to drive longer and faster, and more people are driving than ever. Understanding how these variables affect each other is critical to making US roads safer, and developing effective strategies for reducing fatality rates.

[1] https://www.census.gov/popclock/

[2] https://en.wikipedia.org/wiki/Motor_vehicle_fatality_rate_in_U.S._by_year

[3] https://blog.americansafetycouncil.com/the-history-of-speed-limits-in-america/#:~:text=The%20National%20Limit%20of%2055,for%20all%20states%20in%201974.
